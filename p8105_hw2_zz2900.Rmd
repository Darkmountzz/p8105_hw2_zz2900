---
title: "Homework 2"
author: "Zhenyu Zhou"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(collapse = TRUE, message = FALSE)
```

```{r load_libraries}
library(tidyverse)
library(readxl)
```


### Problem 1

Below we import and clean data from `NYC_Transit_Subway_Entrance_And_Exit_Data.csv`. The process begins with data import, updates variable names, and selects the columns that will be used in later parts fo this problem. We update `entry` from `yes` / `no` to a logical variable. As part of data import, we specify that `Route` columns 8-11 should be character for consistency with 1-7.

```{r}
Transit = read_csv("data/NYC_Transit_Subway_Entrance_And_Exit_Data.csv",
    col_types = cols(Route8 = "c", Route9 = "c", Route10 = "c", Route11 = "c")) %>% 
  janitor::clean_names() %>% 
  select(line, station_name, station_latitude, station_longitude, 
    starts_with("route"), entry, exit_only, vending, entrance_type, 
    ada) %>% 
  mutate(entry = ifelse(entry == "YES", TRUE, FALSE))
```

As it stands, these data are not "tidy": route number should be a variable, as should route. That is, to obtain a tidy dataset we would need to convert `route` variables from wide to long format. This will be useful when focusing on specific routes, but may not be necessary when considering questions that focus on station-level variables. 

The following code chunk selects station name and line, and then uses `distinct()` to obtain all unique combinations. As a result, the number of rows in this dataset is the number of unique stations.

```{r}
Transit %>% 
  select(station_name, line) %>% 
  distinct
```

The next code chunk is similar, but filters according to ADA compliance as an initial step. This produces a dataframe in which the number of rows is the number of ADA compliant stations. 

```{r}
Transit %>% 
  filter(ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

To compute the proportion of station entrances / exits without vending allow entrance, we first exclude station entrances that do not allow vending. Then, we focus on the `entry` variable -- this logical, so taking the mean will produce the desired proportion (recall that R will coerce logical to numeric in cases like this).

```{r}
Transit %>% 
  filter(vending == "NO") %>% 
  pull(entry) %>% 
  mean
```

Lastly, we write a code chunk to identify stations that serve the A train, and to assess how many of these are ADA compliant. As a first step, we tidy the data as alluded to previously; that is, we convert `route` from wide to long format. After this step, we can use tools from previous parts of the question (filtering to focus on the A train, and on ADA compliance; selecting and using `distinct` to obtain dataframes with the required stations in rows).

```{r}
Transit %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A") %>% 
  select(station_name, line) %>% 
  distinct
```

```{r}
Transit %>% 
  pivot_longer(
    route1:route11,
    names_to = "route_num",
    values_to = "route") %>% 
  filter(route == "A", ada == TRUE) %>% 
  select(station_name, line) %>% 
  distinct
```

# Problem 2 

First Step: Read and clean the Mr. Trash Wheel sheet

```{r}
# The mutate function indicates which sheet is from
# The row with pic was excluded
Trash_data = read_excel(
  "data/Trash Wheel Collection Data.xlsx", 
  sheet ="Mr. Trash Wheel", 
  range = "A2:N549"
) %>%
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(sports_balls, sports_balls = as.integer(round(sports_balls, digits = 0))) %>% 
  mutate(group = 1 ) %>% 
  mutate(year = as.numeric(year))
```

Second Step:Read and clean the Professor Trash Wheel sheet

```{r}
Professor_data = read_excel(
  "data/Trash Wheel Collection Data.xlsx",
  sheet ="Professor Trash Wheel", 
  range = "A2:M96") %>%
  janitor::clean_names() %>% 
  drop_na(dumpster) %>% 
  mutate(group = 2)
```

Third Step: Combine two dataset and do calculation

```{r}
merge_data = bind_rows(Trash_data, Professor_data)
total = filter(merge_data, group == "2") %>%
  pull(weight_tons)
ball = filter(merge_data , group == "1"& year == "2020") %>% 
  pull(sports_balls)

```


For the first data set, Mr. Trash Wheel contains `r nrow(Trash_data)` observations with `r ncol(Trash_data)` variables: `r names(Trash_data)`

For the second data set, Professor Trash Wheel contains `r nrow(Professor_data)` observations with `r ncol(Professor_data)` variables: `r names(Professor_data)`

For the merge data set, it contains `r nrow(merge_data)` observations with `r ncol(merge_data)` variables: `r names(merge_data)`

Therefore, the total weight of trash collected by Professor Trash Wheel is `r sum(total)` tons. The total number of sports balls collected by Mr.Trash Wheel in 2020 is `r sum(ball)`.

## Problem 3

First Step: Clean data in pols-month.csv.

```{r}
pols_month = read_csv("./data/fivethirtyeight_datasets/pols-month.csv",show_col_types = FALSE) %>% 
  janitor::clean_names() %>% 
  separate(mon, into = c("year", "month","day")) %>%
  mutate(
    month = as.integer(month),
    year = as.integer(year),
    month = month.name[month]
  ) %>% 
  mutate(president = if_else(prez_gop == 0, "dem", "gop")) %>%
  select(-prez_dem, -prez_gop, -day)
```

Second Step: Clean data in snp.csv.

```{r}
snp = read_csv("./data/fivethirtyeight_datasets/snp.csv", show_col_types = FALSE) %>% 
  janitor::clean_names() %>% 
  mutate(date = lubridate::mdy(date)) %>% 
  separate(date, into = c("year", "month","day")) %>%
  mutate(month = as.integer(month),
         month = month.name[month],
         day = as.integer(day),
         year = as.integer(year),
         year = ifelse(year > 2021, year - 100, year)) %>%
  select(-day) %>% 
  relocate(year, month) %>%
  arrange(year, month)
```

Third Step: Tidy the unemployment data 

```{r}
unemploy = read_csv("./data/fivethirtyeight_datasets/unemployment.csv") %>%
  pivot_longer(
    Jan:Dec,
    names_to = "month",
    values_to = "unemployment") %>%
  janitor::clean_names() %>%
  mutate(month = month.name[match(month,month.abb)])
```

Join the datasets by merging snp into pols, and merging unemployment into the result.

```{r}
merge_data = left_join(pols_month, snp) %>% left_join(unemploy) 
```

Therefore:
  
  For the pols_month dataset, the dimension of the dataset is `r dim(pols_month)`, the range of years is `r range(pull(pols_month, year))`, the key variables contains `r names(pols_month)`.

For the snp dataset, the dimension of the dataset is `r dim(snp)`, the range of years is `r range(pull(snp, year))`, the key variables contains `r names(snp)`.

For the unemployment dataset, the dimension of the dataset is `r dim(unemploy)`, the range of years is `r range(pull(unemploy, year))`, the key variables contains `r names(unemploy)`.

For the merging datasets, the dimension of the dataset is `r dim(merge_data)`, the range of years is `r range(pull(merge_data, year))`, the key variables contains `r names(merge_data)`.

